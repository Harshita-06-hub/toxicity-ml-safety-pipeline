{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1hJ9l1OhhbS_Ah59jILiz6dLpIXNXDYxZ","timestamp":1768910484976}],"authorship_tag":"ABX9TyMNn6FZHJQyfvL5xoczYN5G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    roc_auc_score, confusion_matrix, classification_report\n",")\n","\n","def run_phase_f():\n","    \"\"\"\n","    Executes Phase F: Baseline Modeling and Evaluation.\n","    Trains a Logistic Regression baseline with class balancing.\n","    \"\"\"\n","    print(f\"--- Starting PHASE F: Baseline Modeling and Evaluation ---\")\n","\n","    # 1. Defensive Programming: Verify Pre-conditions\n","    # Check if X and y exist in the global scope (from Phase E)\n","    assert 'X' in globals(), \"CRITICAL ERROR: Feature matrix X not found. Run Phase E first.\"\n","    assert 'y' in globals(), \"CRITICAL ERROR: Label vector y not found. Run Phase E first.\"\n","\n","    # 7. Train-Test Split\n","    print(f\"[Setup] Splitting data 80/20 (Stratified)...\")\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y,\n","        test_size=0.20,\n","        stratify=y,\n","        random_state=42\n","    )\n","\n","    print(f\" -> Training Set: {X_train.shape[0]} samples\")\n","    print(f\" -> Test Set:     {X_test.shape[0]} samples\")\n","\n","    # 10. Initialize Model\n","    # Using 'balanced' class weights to handle the severe imbalance\n","    print(f\"[Training] Training Logistic Regression (class_weight='balanced')...\")\n","    model = LogisticRegression(\n","        class_weight='balanced',\n","        max_iter=1000,\n","        solver='liblinear',\n","        random_state=42\n","    )\n","\n","    # Train the model\n","    model.fit(X_train, y_train)\n","\n","    # Predictions\n","    y_pred = model.predict(X_test)\n","    y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class (Toxic)\n","\n","    # 12. Evaluation Metrics\n","    print(f\"\\n\" + \"=\"*45)\n","    print(f\"          MODEL EVALUATION REPORT\")\n","    print(f\"=\"*45)\n","\n","    # Calculate metrics\n","    acc = accuracy_score(y_test, y_pred)\n","    prec = precision_score(y_test, y_pred)\n","    rec = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    roc = roc_auc_score(y_test, y_prob)\n","\n","    print(f\"Accuracy:          {acc:.4f}\")\n","    print(f\"ROC-AUC:           {roc:.4f}\")\n","    print(f\"-\"*45)\n","    print(f\"Precision (Toxic): {prec:.4f}\")\n","    print(f\"Recall (Toxic):    {rec:.4f}  <-- CRITICAL METRIC\")\n","    print(f\"F1-Score (Toxic):  {f1:.4f}\")\n","    print(f\"=\"*45)\n","\n","    # 13. Classification Report\n","    print(f\"\\n[Detailed Classification Report]\")\n","    print(classification_report(y_test, y_pred, target_names=['Non-Toxic (0)', 'Toxic (1)']))\n","\n","    # 14. Confusion Matrix\n","    cm = confusion_matrix(y_test, y_pred)\n","    tn, fp, fn, tp = cm.ravel()\n","\n","    print(f\"\\n[Confusion Matrix]\")\n","    print(f\"                 Predicted 0   Predicted 1\")\n","    print(f\"Actual 0 (Safe)      {tn:<5}         {fp:<5}\")\n","    print(f\"Actual 1 (Toxic)     {fn:<5}         {tp:<5}\")\n","    print(f\"\\n -> False Negatives (Missed Toxins): {fn}\")\n","    print(f\" -> False Positives (False Alarms):  {fp}\")\n","\n","    # 15. Scientific Interpretation\n","    print(f\"\\n\" + \"-\"*60)\n","    print(f\"SCIENTIFIC INTERPRETATION:\")\n","    print(f\"-\"*60)\n","    print(f\"1. Recall vs. Accuracy:\")\n","    print(f\"   Accuracy ({acc:.2%}) is less important than Recall ({rec:.2%}) here.\")\n","    print(f\"   In toxicology, our primary goal is to catch toxic molecules.\")\n","\n","    print(f\"\\n2. The Cost of False Negatives:\")\n","    print(f\"   The model missed {fn} toxic molecules (False Negatives).\")\n","    print(f\"   These represent potential safety failures in drug discovery.\")\n","    print(f\"   A high Recall minimizes these dangerous misses.\")\n","\n","    print(f\"\\n3. Baseline Performance:\")\n","    print(f\"   Using class_weight='balanced' forces the model to pay attention\")\n","    print(f\"   to the minority class, often trading some Precision for higher Recall.\")\n","    print(f\"-\"*60)\n","\n","    return model, X_test, y_test, y_pred, y_prob\n","\n","# --- EXECUTION ---\n","\n","# Execute logic and assign to global variables for potential future use\n","lr_model, X_test, y_test, y_pred_baseline, y_prob_baseline = run_phase_f()\n","\n","# 18. Final Success Message\n","print(f\"\\n--- PHASE F COMPLETED SUCCESSFULLY ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7l1ybzuRFrUy","executionInfo":{"status":"ok","timestamp":1768910638506,"user_tz":-330,"elapsed":624,"user":{"displayName":"HARSHITA SINGH","userId":"14936722242365284836"}},"outputId":"1fe26de1-cf4c-430b-bb72-915b4add73cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting PHASE F: Baseline Modeling and Evaluation ---\n","[Setup] Splitting data 80/20 (Stratified)...\n"," -> Training Set: 1168 samples\n"," -> Test Set:     293 samples\n","[Training] Training Logistic Regression (class_weight='balanced')...\n","\n","=============================================\n","          MODEL EVALUATION REPORT\n","=============================================\n","Accuracy:          0.9215\n","ROC-AUC:           0.8598\n","---------------------------------------------\n","Precision (Toxic): 0.4444\n","Recall (Toxic):    0.3810  <-- CRITICAL METRIC\n","F1-Score (Toxic):  0.4103\n","=============================================\n","\n","[Detailed Classification Report]\n","               precision    recall  f1-score   support\n","\n","Non-Toxic (0)       0.95      0.96      0.96       272\n","    Toxic (1)       0.44      0.38      0.41        21\n","\n","     accuracy                           0.92       293\n","    macro avg       0.70      0.67      0.68       293\n"," weighted avg       0.92      0.92      0.92       293\n","\n","\n","[Confusion Matrix]\n","                 Predicted 0   Predicted 1\n","Actual 0 (Safe)      262           10   \n","Actual 1 (Toxic)     13            8    \n","\n"," -> False Negatives (Missed Toxins): 13\n"," -> False Positives (False Alarms):  10\n","\n","------------------------------------------------------------\n","SCIENTIFIC INTERPRETATION:\n","------------------------------------------------------------\n","1. Recall vs. Accuracy:\n","   Accuracy (92.15%) is less important than Recall (38.10%) here.\n","   In toxicology, our primary goal is to catch toxic molecules.\n","\n","2. The Cost of False Negatives:\n","   The model missed 13 toxic molecules (False Negatives).\n","   These represent potential safety failures in drug discovery.\n","   A high Recall minimizes these dangerous misses.\n","\n","3. Baseline Performance:\n","   Using class_weight='balanced' forces the model to pay attention\n","   to the minority class, often trading some Precision for higher Recall.\n","------------------------------------------------------------\n","\n","--- PHASE F COMPLETED SUCCESSFULLY ---\n"]}]}]}